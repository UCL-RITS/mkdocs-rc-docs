---
title: Running LAMMPS on Legion
categories:
 - Bash script pages
 - Legion

layout: docs
---
[[Category:Bash script pages]]
[[Category:Legion]]
The build of LAMMPS on Legion was build with double precision FFTW, the OpenMPI library and the Intel 13.0 compilers.  It is therefore strongly recommended that you have these modules loaded when running it:

* sge/6.2u3
* compilers/intel/13.0/028_cxx11
* mpi/openmpi/1.4.5/intel.13.0
* fftw/2.1.5/double/intel.13.0
* lammps/7Jun13/openmpi/intel.13.0

The last four of those modules are not loaded by default and (will conflict with default loaded modules), but may be loaded in your job script. If you are using the default modules remember to unload them in your script before loading the modules above.

An example job script for LAMMPS is shown below:
{|style="background-color:#F9F9F9;" width=100%
|-
|
<code>
 #!/bin/bash -l

 # Batch script to run an MPI parallel job on Legion with the upgraded software
 # stack under SGE with OpenMPI.

 # 1. Force bash as the executing shell.
 #$ -S /bin/bash

 # 2. Request one hour of wallclock time (format hours:minutes:seconds).
 #$ -l h_rt=1:00:00

 # 3. Request 1 gigabyte of RAM per process.
 #$ -l mem=1G

 # 4. Set the name of the job.
 #$ -N ExampleLAMMPS

 # 5. Select the QLogic parallel environment and 24 processes.
 #$ -pe openmpi 24

 # 6. Select the project that this job will run under.
 # Find <your_project_id> by running the command "groups"
 #$ -P <your_project_id>

 # 7. Set the working directory to somewhere in your scratch space.  This is
 # a necessary step with the upgraded software stack as compute nodes cannot
 # write to $HOME.
 # Replace "<your_UCL_id>" with your UCL user ID.
 #$ -wd /home/<your_UCL_id>/Scratch/lammps

 # 8. Load required modules 

 # If you have default modules loaded, uncomment lines below:
 # module remove default-modules
 # module load sge

 module load compilers/intel/13.0/028_cxx11
 module load mpi/openmpi/1.4.5/intel.13.0
 module load fftw/2.1.5/double/intel.13.0
 module load lammps/7Jun13/openmpi/intel.13.0

 # 9. Run our MPI job.  Replace "inputfile" with the name of your LAMMPS input file.
 gerun `which lmp_legion` -in inputfile
</code>
|}